{"timestamp":"2025-11-03T22:00:41.903693Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2025-11-03T22:00:41.904510Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/migracao_rh.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2025-11-03T22:00:41.940493Z","level":"warning","event":"The `airflow.models.baseoperator.cross_downstream` attribute is deprecated. Please use `'airflow.sdk.bases.operator.cross_downstream'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/migracao_rh.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2025-11-03T22:00:41.981302Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2025-11-03T22:00:41.981495Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2025-11-03T22:00:41.981575Z","level":"info","event":"Current task name:load_funcionarios","logger":"task.stdout"}
{"timestamp":"2025-11-03T22:00:41.981611Z","level":"info","event":"Dag name:postgreSQL_to_MySQL","logger":"task.stdout"}
{"timestamp":"2025-11-03T22:00:42.056501Z","level":"info","event":"Running statement: \n        INSERT INTO funcionarios (id, nome, email, cpf, data_admissao, id_cargo, id_departamento)\n        VALUES (%s, %s, %s, %s, %s, %s, %s)\n        ON DUPLICATE KEY UPDATE\n            nome = VALUES(nome),\n            cpf = VALUES(cpf),\n            data_admissao = VALUES(data_admissao),\n            id_cargo = VALUES(id_cargo),\n            id_departamento = VALUES(id_departamento)\n    , parameters: (1, 'Ana Souza', 'anasouzateste@email.com', '123.456.789-00', '2021-02-10T00:00:00.000', 1, 1)","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":810}
{"timestamp":"2025-11-03T22:00:42.058416Z","level":"info","event":"Rows affected: 0","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":822}
{"timestamp":"2025-11-03T22:00:42.067887Z","level":"info","event":"Running statement: \n        INSERT INTO funcionarios (id, nome, email, cpf, data_admissao, id_cargo, id_departamento)\n        VALUES (%s, %s, %s, %s, %s, %s, %s)\n        ON DUPLICATE KEY UPDATE\n            nome = VALUES(nome),\n            cpf = VALUES(cpf),\n            data_admissao = VALUES(data_admissao),\n            id_cargo = VALUES(id_cargo),\n            id_departamento = VALUES(id_departamento)\n    , parameters: (2, 'Bruno Oliveira', 'brunooliveirateste@email.com', '987.654.321-00', '2020-06-15T00:00:00.000', 2, 2)","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":810}
{"timestamp":"2025-11-03T22:00:42.069146Z","level":"info","event":"Rows affected: 0","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":822}
{"timestamp":"2025-11-03T22:00:42.077855Z","level":"info","event":"Running statement: \n        INSERT INTO funcionarios (id, nome, email, cpf, data_admissao, id_cargo, id_departamento)\n        VALUES (%s, %s, %s, %s, %s, %s, %s)\n        ON DUPLICATE KEY UPDATE\n            nome = VALUES(nome),\n            cpf = VALUES(cpf),\n            data_admissao = VALUES(data_admissao),\n            id_cargo = VALUES(id_cargo),\n            id_departamento = VALUES(id_departamento)\n    , parameters: (3, 'Carlos Silva', 'carlossilvateste@email.com', '111.222.333-44', '2022-03-01T00:00:00.000', 3, 3)","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":810}
{"timestamp":"2025-11-03T22:00:42.079544Z","level":"info","event":"Rows affected: 0","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":822}
{"timestamp":"2025-11-03T22:00:42.088354Z","level":"info","event":"Running statement: \n        INSERT INTO funcionarios (id, nome, email, cpf, data_admissao, id_cargo, id_departamento)\n        VALUES (%s, %s, %s, %s, %s, %s, %s)\n        ON DUPLICATE KEY UPDATE\n            nome = VALUES(nome),\n            cpf = VALUES(cpf),\n            data_admissao = VALUES(data_admissao),\n            id_cargo = VALUES(id_cargo),\n            id_departamento = VALUES(id_departamento)\n    , parameters: (4, 'Daniela Mendes', 'danielamendesteste@email.com', '555.666.777-88', '2019-10-20T00:00:00.000', 4, 4)","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":810}
{"timestamp":"2025-11-03T22:00:42.090053Z","level":"info","event":"Rows affected: 0","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":822}
{"timestamp":"2025-11-03T22:00:42.099583Z","level":"info","event":"Running statement: \n        INSERT INTO funcionarios (id, nome, email, cpf, data_admissao, id_cargo, id_departamento)\n        VALUES (%s, %s, %s, %s, %s, %s, %s)\n        ON DUPLICATE KEY UPDATE\n            nome = VALUES(nome),\n            cpf = VALUES(cpf),\n            data_admissao = VALUES(data_admissao),\n            id_cargo = VALUES(id_cargo),\n            id_departamento = VALUES(id_departamento)\n    , parameters: (5, 'Eduardo Lima', 'eduardolimateste@email.com', '999.888.777-66', '2021-08-05T00:00:00.000', 5, 3)","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":810}
{"timestamp":"2025-11-03T22:00:42.101023Z","level":"info","event":"Rows affected: 0","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":822}
{"timestamp":"2025-11-03T22:00:42.102993Z","level":"info","event":"Done. Returned value was: None","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator","filename":"python.py","lineno":218}
{"timestamp":"2025-11-03T22:00:42.136680Z","level":"info","event":"Task instance in success state","logger":"task.stdout"}
{"timestamp":"2025-11-03T22:00:42.136897Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","logger":"task.stdout"}
{"timestamp":"2025-11-03T22:00:42.137155Z","level":"info","event":"Task operator:<Task(PythonOperator): load_funcionarios>","logger":"task.stdout"}
