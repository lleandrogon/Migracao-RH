{"timestamp":"2025-11-03T21:51:23.188049Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2025-11-03T21:51:23.188668Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/migracao_rh.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2025-11-03T21:51:23.222051Z","level":"warning","event":"The `airflow.models.baseoperator.cross_downstream` attribute is deprecated. Please use `'airflow.sdk.bases.operator.cross_downstream'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/migracao_rh.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2025-11-03T21:51:23.252283Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2025-11-03T21:51:23.252503Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2025-11-03T21:51:23.252588Z","level":"info","event":"Current task name:load_salarios","logger":"task.stdout"}
{"timestamp":"2025-11-03T21:51:23.252624Z","level":"info","event":"Dag name:postgreSQL_to_MySQL","logger":"task.stdout"}
{"timestamp":"2025-11-03T21:51:23.316721Z","level":"info","event":"Running statement: \n        INSERT INTO salarios (id, id_funcionario, valor, data_inicio, data_fim)\n        VALUES (%s, %s, %s, %s, %s)\n        ON DUPLICATE KEY UPDATE\n            id_funcionario = VALUES(id_funcionario),\n            valor = VALUES(valor),\n            data_inicio = VALUES(data_inicio),\n            data_fim = VALUES(data_fim)\n    , parameters: (1, 1, 5000, '2021-02-10T00:00:00.000', None)","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":810}
{"timestamp":"2025-11-03T21:51:23.320417Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":822}
{"timestamp":"2025-11-03T21:51:23.331293Z","level":"info","event":"Running statement: \n        INSERT INTO salarios (id, id_funcionario, valor, data_inicio, data_fim)\n        VALUES (%s, %s, %s, %s, %s)\n        ON DUPLICATE KEY UPDATE\n            id_funcionario = VALUES(id_funcionario),\n            valor = VALUES(valor),\n            data_inicio = VALUES(data_inicio),\n            data_fim = VALUES(data_fim)\n    , parameters: (2, 2, 9500, '2020-06-15T00:00:00.000', None)","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":810}
{"timestamp":"2025-11-03T21:51:23.333374Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":822}
{"timestamp":"2025-11-03T21:51:23.344301Z","level":"info","event":"Running statement: \n        INSERT INTO salarios (id, id_funcionario, valor, data_inicio, data_fim)\n        VALUES (%s, %s, %s, %s, %s)\n        ON DUPLICATE KEY UPDATE\n            id_funcionario = VALUES(id_funcionario),\n            valor = VALUES(valor),\n            data_inicio = VALUES(data_inicio),\n            data_fim = VALUES(data_fim)\n    , parameters: (3, 3, 7500, '2022-03-01T00:00:00.000', None)","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":810}
{"timestamp":"2025-11-03T21:51:23.346880Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":822}
{"timestamp":"2025-11-03T21:51:23.356506Z","level":"info","event":"Running statement: \n        INSERT INTO salarios (id, id_funcionario, valor, data_inicio, data_fim)\n        VALUES (%s, %s, %s, %s, %s)\n        ON DUPLICATE KEY UPDATE\n            id_funcionario = VALUES(id_funcionario),\n            valor = VALUES(valor),\n            data_inicio = VALUES(data_inicio),\n            data_fim = VALUES(data_fim)\n    , parameters: (4, 4, 5500, '2019-10-20T00:00:00.000', None)","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":810}
{"timestamp":"2025-11-03T21:51:23.357708Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":822}
{"timestamp":"2025-11-03T21:51:23.369294Z","level":"info","event":"Running statement: \n        INSERT INTO salarios (id, id_funcionario, valor, data_inicio, data_fim)\n        VALUES (%s, %s, %s, %s, %s)\n        ON DUPLICATE KEY UPDATE\n            id_funcionario = VALUES(id_funcionario),\n            valor = VALUES(valor),\n            data_inicio = VALUES(data_inicio),\n            data_fim = VALUES(data_fim)\n    , parameters: (5, 5, 7300, '2021-08-05T00:00:00.000', None)","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":810}
{"timestamp":"2025-11-03T21:51:23.371225Z","level":"info","event":"Rows affected: 1","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":822}
{"timestamp":"2025-11-03T21:51:23.374342Z","level":"info","event":"Done. Returned value was: None","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator","filename":"python.py","lineno":218}
{"timestamp":"2025-11-03T21:51:23.406657Z","level":"info","event":"Task instance in success state","logger":"task.stdout"}
{"timestamp":"2025-11-03T21:51:23.406826Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","logger":"task.stdout"}
{"timestamp":"2025-11-03T21:51:23.406925Z","level":"info","event":"Task operator:<Task(PythonOperator): load_salarios>","logger":"task.stdout"}
