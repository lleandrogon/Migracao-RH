{"timestamp":"2025-11-04T18:59:04.265502Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2025-11-04T18:59:04.268830Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/migracao_rh.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2025-11-04T18:59:04.374027Z","level":"warning","event":"The `airflow.models.baseoperator.cross_downstream` attribute is deprecated. Please use `'airflow.sdk.bases.operator.cross_downstream'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/migracao_rh.py","lineno":4,"logger":"py.warnings"}
{"timestamp":"2025-11-04T18:59:04.520324Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2025-11-04T18:59:04.520642Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2025-11-04T18:59:04.520850Z","level":"info","event":"Current task name:load_departamentos","logger":"task.stdout"}
{"timestamp":"2025-11-04T18:59:04.520925Z","level":"info","event":"Dag name:postgreSQL_to_MySQL","logger":"task.stdout"}
{"timestamp":"2025-11-04T18:59:04.802201Z","level":"info","event":"Running statement: \n        INSERT INTO departamentos (id, nome, cidade, uf)\n        VALUES (%s, %s, %s, %s)\n        ON DUPLICATE KEY UPDATE\n            nome = VALUES(nome),\n            cidade = VALUES(cidade),\n            uf = VALUES(uf)\n    , parameters: (1, 'Recursos Humanos', 'São Paulo', 'SP')","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":810}
{"timestamp":"2025-11-04T18:59:04.807946Z","level":"info","event":"Rows affected: 0","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":822}
{"timestamp":"2025-11-04T18:59:04.831306Z","level":"info","event":"Running statement: \n        INSERT INTO departamentos (id, nome, cidade, uf)\n        VALUES (%s, %s, %s, %s)\n        ON DUPLICATE KEY UPDATE\n            nome = VALUES(nome),\n            cidade = VALUES(cidade),\n            uf = VALUES(uf)\n    , parameters: (2, 'Financeiro', 'Rio de Janeiro', 'RJ')","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":810}
{"timestamp":"2025-11-04T18:59:04.835079Z","level":"info","event":"Rows affected: 0","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":822}
{"timestamp":"2025-11-04T18:59:04.855644Z","level":"info","event":"Running statement: \n        INSERT INTO departamentos (id, nome, cidade, uf)\n        VALUES (%s, %s, %s, %s)\n        ON DUPLICATE KEY UPDATE\n            nome = VALUES(nome),\n            cidade = VALUES(cidade),\n            uf = VALUES(uf)\n    , parameters: (3, 'Tecnologia da Informação', 'Curitiba', 'PR')","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":810}
{"timestamp":"2025-11-04T18:59:04.859229Z","level":"info","event":"Rows affected: 0","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":822}
{"timestamp":"2025-11-04T18:59:04.886173Z","level":"info","event":"Running statement: \n        INSERT INTO departamentos (id, nome, cidade, uf)\n        VALUES (%s, %s, %s, %s)\n        ON DUPLICATE KEY UPDATE\n            nome = VALUES(nome),\n            cidade = VALUES(cidade),\n            uf = VALUES(uf)\n    , parameters: (4, 'Marketing', 'Belo Horizonte', 'MG')","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":810}
{"timestamp":"2025-11-04T18:59:04.890915Z","level":"info","event":"Rows affected: 0","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook","filename":"sql.py","lineno":822}
{"timestamp":"2025-11-04T18:59:04.898590Z","level":"info","event":"Done. Returned value was: None","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator","filename":"python.py","lineno":218}
{"timestamp":"2025-11-04T18:59:04.980634Z","level":"info","event":"Task instance in success state","logger":"task.stdout"}
{"timestamp":"2025-11-04T18:59:04.981116Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","logger":"task.stdout"}
{"timestamp":"2025-11-04T18:59:04.981468Z","level":"info","event":"Task operator:<Task(PythonOperator): load_departamentos>","logger":"task.stdout"}
